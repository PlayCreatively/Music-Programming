# 1. Strategic AI Briefing Documentation (500–600 words)
Document how you provided context to AI tools, including your initial project brief,
technical constraints, and creative goals. Include:

- [ ] a. Your initial project brief given to AI tools
- [ ] b. Examples of how you provided SuperCollider/DSP context
- [ ] c. Evidence of how you refined your prompting approach



---
# 2. Example Prompts and AI Outputs (800–1000 words)
Provide 4–5 detailed examples of AI interactions that were significant to your project
development. For each example include:

- [ ] a. The exact prompt you used (in code blocks)
- [ ] b. The AI’s response/output (in code blocks)
- [ ] c. Your reflective commentary on the quality and usefulness of the response
- [ ] d. How you modified or used the AI’s suggestion

---
# 3. Critical Filtering and Decision Making (400–500 words)
Document specific instances where you rejected or significantly modified AI
suggestions. Include:

- [ ] a. At least 2 examples of AI outputs you rejected with your reasoning
- [ ] b. Examples of code you modified or improved from AI suggestions
- [ ] c. Your criteria for evaluating AI suggestions in audio programming contexts

---
# 4. Collaboration Strategy Reflection

> [!INFO]
> As agreed with my supervisor, Matt Bellingham, the following section will look the same for both Audio Programming and Sound and Music Programming as both projects were worked on in tandem and differentiating between my LLM collaboration approaches would be difficult and frankly disingenuous, as they were one in the same. 

The collaboration was at its best when I was able to abstract individual generic problems from the project and tackle it in isolation using an LLM as a thinking partner. Once that problem is solved, implementing it manually as a generic function guarantees that you retain ownership and full comprehension of the whole codebase.

What can sadly happen is that time constraints and anxieties will steer you towards taking shortcuts and working in a somewhat reverse order: getting the LLM to work on the whole solution until you get to the desired goal and then retroactively study and refactor the code base. This may take more time in the long run, but in the short term it can sooth your anxieties about going down a null route. 

I tried to get the LLM to work in a way that facilitated the former approach, however, their underlying incentive is predisposed to do the work for you and spit out working code. It is not yet capable of reprograming itself to slow down and have a human-like dialogue where its making sure you're following along as opposed to throwing a whole assay at you, hoping it's covering all potential future questions you might have.

Creatively, it affords you to stay more in the high level thinking than the implementation level, freeing you from the limitations of your own knowledge and capability as well as the tunnel vision that the implementation level traps you in.

For a long time, professions relating to programming have had the unavoidable affordance of shortcuts, be it writing solutions based on intuition alone or brute-forced debugging which leads to solutions you can't explain. Later on, since the introduction of the internet (and websites such as [stackoverflow.com](https://stackoverflow.com/)), outsourcing your solutions to fellow programmers have become easier, and now, at the dawn of LLMs, as they creep into our tools, it has become close to impossible to not make use of the speed boost.
However, this is only relevant to jobs for which not enough time has been allocated, and as long as jobs have fast approaching deadlines, shortcuts will be taken.

---
# Annotation Integration
Your AI collaboration portfolio must also include a reflective annotation that addresses the
following:
1. [ ] Original Aims: What were your original aims for your artefact? Who is it for and/or what is it designed to do? You may refer to a persona or a "Jobs To Be Done" (JTBD) framework. Heuristics can be useful in specifying the desired behaviour of your artefact.
2. [ ] Influences: What existing tools influenced your thinking and implementation (e.g. NIME tools, commercial software)? What did you learn from them, and how have they shaped your work?
3. [ ] Implementation Process: How did you approach the implementation phase? What decisions did you make? Were any viability tests required to select hardware/software? What problems did you encounter, and how did you overcome or work around them?
4. [ ] Evaluation: Evaluate your finished artefact against your original aims and/or heuristics. Which elements are you most proud of? What would you change if you had more time, and how?
5. [ ] References: Compile an APA-formatted reference list that includes well-chosen technical sources and details of the tools that influenced your work. All code examples should be properly formatted using Markdown code blocks with appropriate syntax highlighting.